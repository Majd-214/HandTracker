import time
from ctypes import cast, POINTER

import cv2
import numpy as np
from comtypes import CLSCTX_ALL
from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume

import HandTrackingModule as Htm

devices = AudioUtilities.GetSpeakers()
interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)
volume = cast(interface, POINTER(IAudioEndpointVolume))

vol_bar = 400
vol_per = 0
area = 0
color_indicator = (255, 0, 0)

cap = cv2.VideoCapture(0)
detector = Htm.HandDetector(max_hands=1, detection_con=0.6)
previous_time = 0

while True:
    success, img = cap.read()

    # Find Hand
    img = detector.find_hands(img, True)
    pos_list, bounding_box = detector.find_position(img, draw_lm=False, draw_box=True)
    current_volume = int(volume.GetMasterVolumeLevelScalar() * 100)

    if len(pos_list) != 0:

        # Filter based on size
        box_width, box_height = bounding_box[1][0] - bounding_box[0][0], bounding_box[1][1] - bounding_box[0][1]
        area = box_width * box_height // 100
        # print(bounding_box, box_width, box_height, area)
        if 200 < area < 1000:

            # Find distance between index and thumb
            length, lineinfo = detector.find_distance(img, 4, 8)

            # Convert Volume
            vol_per = np.interp(length, [30, 200], [0, 100])

            # Reduce resolution to increase usability
            increment = 10
            vol_per = increment * round(vol_per / increment)
            vol_bar = np.interp(vol_per, [0, 100], [400, 150])

            # Check fingers Up/Down
            fingers = detector.fingers_up()

            # If pinkie is down, set volume
            if not fingers[4]:
                volume.SetMasterVolumeLevelScalar((vol_per / 100), None)
                current_volume = int(volume.GetMasterVolumeLevelScalar() * 100)
                if current_volume % 10 != 0:
                    volume.SetMasterVolumeLevelScalar((vol_per / 100) + 0.01, None)
                    current_volume = int(volume.GetMasterVolumeLevelScalar() * 100)
                color_indicator = (0, 255, 0)
            else:
                color_indicator = (255, 0, 0)
            cv2.circle(img, (lineinfo[4], lineinfo[5]), 10, color_indicator, cv2.FILLED)

            # Drawings
            cv2.rectangle(img, (50, 150), (85, 400), (255, 0, 0), 3)
            cv2.rectangle(img, (50, int(vol_bar)), (85, 400), (255, 0, 0), cv2.FILLED)

    # Frame rate
    current_time = time.time()
    fps = 1 / (current_time - previous_time)
    previous_time = current_time

    cv2.putText(img, f'FPS: {int(fps)}', (10, 70), cv2.FONT_HERSHEY_DUPLEX, 1, (255, 0, 0), 3)
    cv2.putText(img, f'{int(vol_per)}%', (40, 450), cv2.FONT_HERSHEY_DUPLEX, 1, (255, 0, 0), 3)
    cv2.putText(img, f'Volume Set: {int(current_volume)}%', (320, 70), cv2.FONT_HERSHEY_DUPLEX, 1, color_indicator, 3)

    # Display
    cv2.imshow("Webcam", img)
    cv2.waitKey(1)
